{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1208c6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T13:43:33.259452Z",
     "iopub.status.busy": "2025-08-08T13:43:33.258803Z",
     "iopub.status.idle": "2025-08-08T13:43:38.425573Z",
     "shell.execute_reply": "2025-08-08T13:43:38.424374Z"
    },
    "papermill": {
     "duration": 5.178247,
     "end_time": "2025-08-08T13:43:38.427522",
     "exception": false,
     "start_time": "2025-08-08T13:43:33.249275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3c513",
   "metadata": {
    "papermill": {
     "duration": 0.007524,
     "end_time": "2025-08-08T13:43:38.443543",
     "exception": false,
     "start_time": "2025-08-08T13:43:38.436019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee5bf79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T13:43:38.460067Z",
     "iopub.status.busy": "2025-08-08T13:43:38.459666Z",
     "iopub.status.idle": "2025-08-08T13:43:55.551840Z",
     "shell.execute_reply": "2025-08-08T13:43:55.550686Z"
    },
    "papermill": {
     "duration": 17.102756,
     "end_time": "2025-08-08T13:43:55.553620",
     "exception": false,
     "start_time": "2025-08-08T13:43:38.450864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import platform\n",
    "import psutil\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ColorJitter, RandomRotation, RandomResizedCrop\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "from PIL import ImageOps\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60c232a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T13:43:55.572497Z",
     "iopub.status.busy": "2025-08-08T13:43:55.572031Z",
     "iopub.status.idle": "2025-08-08T13:43:55.583962Z",
     "shell.execute_reply": "2025-08-08T13:43:55.582957Z"
    },
    "papermill": {
     "duration": 0.023019,
     "end_time": "2025-08-08T13:43:55.585679",
     "exception": false,
     "start_time": "2025-08-08T13:43:55.562660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: x86_64\n",
      "Total RAM (GB): 31.35\n",
      "GPU: No GPU available\n"
     ]
    }
   ],
   "source": [
    "cpu_info = platform.processor()\n",
    "\n",
    "ram_info = psutil.virtual_memory()\n",
    "total_ram_gb = ram_info.total / (1024 ** 3)\n",
    "\n",
    "try:\n",
    "    gpu_info = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "    gpu_name = gpu_info[1]\n",
    "except:\n",
    "    gpu_name = \"No GPU available\"\n",
    "\n",
    "print(\"CPU:\", cpu_info)\n",
    "print(\"Total RAM (GB):\", round(total_ram_gb, 2))\n",
    "print(\"GPU:\", gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb9490",
   "metadata": {
    "papermill": {
     "duration": 0.007566,
     "end_time": "2025-08-08T13:43:55.601660",
     "exception": false,
     "start_time": "2025-08-08T13:43:55.594094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148f13b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T13:43:55.618602Z",
     "iopub.status.busy": "2025-08-08T13:43:55.618266Z",
     "iopub.status.idle": "2025-08-08T13:43:55.630048Z",
     "shell.execute_reply": "2025-08-08T13:43:55.628977Z"
    },
    "papermill": {
     "duration": 0.02211,
     "end_time": "2025-08-08T13:43:55.631793",
     "exception": false,
     "start_time": "2025-08-08T13:43:55.609683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: x86_64\n",
      "Total RAM (GB): 31.35\n",
      "GPU: No GPU available\n"
     ]
    }
   ],
   "source": [
    "cpu_info = platform.processor()\n",
    "\n",
    "ram_info = psutil.virtual_memory()\n",
    "total_ram_gb = ram_info.total / (1024 ** 3)\n",
    "\n",
    "try:\n",
    "    gpu_info = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "    gpu_name = gpu_info[1]\n",
    "except:\n",
    "    gpu_name = \"No GPU available\"\n",
    "\n",
    "print(\"CPU:\", cpu_info)\n",
    "print(\"Total RAM (GB):\", round(total_ram_gb, 2))\n",
    "print(\"GPU:\", gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120fe604",
   "metadata": {
    "papermill": {
     "duration": 0.007399,
     "end_time": "2025-08-08T13:43:55.647284",
     "exception": false,
     "start_time": "2025-08-08T13:43:55.639885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Seed Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea094eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T13:43:55.664467Z",
     "iopub.status.busy": "2025-08-08T13:43:55.664041Z",
     "iopub.status.idle": "2025-08-08T13:43:55.678588Z",
     "shell.execute_reply": "2025-08-08T13:43:55.677508Z"
    },
    "papermill": {
     "duration": 0.025332,
     "end_time": "2025-08-08T13:43:55.680299",
     "exception": false,
     "start_time": "2025-08-08T13:43:55.654967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7c509",
   "metadata": {
    "papermill": {
     "duration": 0.007243,
     "end_time": "2025-08-08T13:43:55.695197",
     "exception": false,
     "start_time": "2025-08-08T13:43:55.687954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa09e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T13:43:55.711999Z",
     "iopub.status.busy": "2025-08-08T13:43:55.711045Z",
     "iopub.status.idle": "2025-08-08T13:43:55.745450Z",
     "shell.execute_reply": "2025-08-08T13:43:55.744278Z"
    },
    "papermill": {
     "duration": 0.044552,
     "end_time": "2025-08-08T13:43:55.747051",
     "exception": true,
     "start_time": "2025-08-08T13:43:55.702499",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/melanoma-cancer-dataset/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/2250073956.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclass_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/melanoma-cancer-dataset/train'"
     ]
    }
   ],
   "source": [
    "data_dir = \"/kaggle/input/melanoma-cancer-dataset/train\"\n",
    "\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        file_paths.append(os.path.join(class_dir, image_name))\n",
    "        labels.append(class_name)\n",
    "\n",
    "df = pd.DataFrame({\"file_path\": file_paths, \"label\": labels})\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7108464b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.069485Z",
     "iopub.status.busy": "2025-07-18T14:25:44.069195Z",
     "iopub.status.idle": "2025-07-18T14:25:44.196522Z",
     "shell.execute_reply": "2025-07-18T14:25:44.195724Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.069461Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_counts_train = df['label'].value_counts()\n",
    "\n",
    "for class_name, count in class_counts_train.items():\n",
    "    print(f\"Class: {class_name}, Count: {count}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = class_counts_train.plot(kind='bar')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Amount of data')\n",
    "plt.xticks(rotation=360)\n",
    "for i, count in enumerate(class_counts_train):\n",
    "    ax.text(i, count + 5, str(count), ha='center')\n",
    "plt.ylim(0, max(class_counts_train) * 1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb1a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.197598Z",
     "iopub.status.busy": "2025-07-18T14:25:44.197280Z",
     "iopub.status.idle": "2025-07-18T14:25:44.541369Z",
     "shell.execute_reply": "2025-07-18T14:25:44.540759Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.197500Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = df['label'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for idx, class_label in enumerate(classes):\n",
    "\n",
    "    class_df = df[df['label'] == class_label]\n",
    "\n",
    "    random_index = random.randint(0, len(class_df) - 1)\n",
    "    random_row = class_df.iloc[random_index]\n",
    "\n",
    "    file_path = random_row['file_path']\n",
    "    label = random_row['label']\n",
    "\n",
    "    image = Image.open(file_path)\n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].set_title(f\"Label: {label}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a33387",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Train-Test-Validation Split (Ratio 70:15:15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb4808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.542548Z",
     "iopub.status.busy": "2025-07-18T14:25:44.542251Z",
     "iopub.status.idle": "2025-07-18T14:25:44.563217Z",
     "shell.execute_reply": "2025-07-18T14:25:44.562589Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.542517Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_dataframe, valid_dataframe = train_test_split(\n",
    "    df,\n",
    "    test_size=0.30, \n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "total = len(df)\n",
    "train_ratio = len(train_dataframe) / total\n",
    "valid_ratio = len(valid_dataframe) / total\n",
    "\n",
    "\n",
    "print(f\"Train: {len(train_dataframe)} ({train_ratio:.2%})\")\n",
    "print(f\"Validation: {len(valid_dataframe)} ({valid_ratio:.2%})\")\n",
    "print(f\"Total: {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02b9d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.566210Z",
     "iopub.status.busy": "2025-07-18T14:25:44.565796Z",
     "iopub.status.idle": "2025-07-18T14:25:44.570381Z",
     "shell.execute_reply": "2025-07-18T14:25:44.569699Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.566190Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Training Data: \", len(train_dataframe))\n",
    "print(\"Validation Data: \", len(valid_dataframe))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Total amount of data in the dataset: \", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f3553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.571251Z",
     "iopub.status.busy": "2025-07-18T14:25:44.571057Z",
     "iopub.status.idle": "2025-07-18T14:25:44.590663Z",
     "shell.execute_reply": "2025-07-18T14:25:44.589849Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.571235Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "class_counts_train = train_dataframe['label'].value_counts()\n",
    "class_counts_valid = valid_dataframe['label'].value_counts()\n",
    "\n",
    "\n",
    "train_table_data = [[class_name, count] for class_name, count in class_counts_train.items()]\n",
    "valid_table_data = [[class_name, count] for class_name, count in class_counts_valid.items()]\n",
    "\n",
    "\n",
    "print(\"Train Dataset\")\n",
    "print(tabulate(train_table_data, headers=[\"Class\", \"Count\"]))\n",
    "print(\"\\nValidation Dataset\")\n",
    "print(tabulate(valid_table_data, headers=[\"Class\", \"Count\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d68a2c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Device Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb18db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.591641Z",
     "iopub.status.busy": "2025-07-18T14:25:44.591345Z",
     "iopub.status.idle": "2025-07-18T14:25:44.603484Z",
     "shell.execute_reply": "2025-07-18T14:25:44.602671Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.591622Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e6a54",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a249975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.604714Z",
     "iopub.status.busy": "2025-07-18T14:25:44.604351Z",
     "iopub.status.idle": "2025-07-18T14:25:44.616871Z",
     "shell.execute_reply": "2025-07-18T14:25:44.616206Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.604690Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path_checkpoints = \"/kaggle/working/\"\n",
    "os.makedirs(save_path_checkpoints, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ed4c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Dataset Class, Dataloader and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fa917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.617861Z",
     "iopub.status.busy": "2025-07-18T14:25:44.617627Z",
     "iopub.status.idle": "2025-07-18T14:25:44.629234Z",
     "shell.execute_reply": "2025-07-18T14:25:44.628648Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.617840Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, normalize, is_lb=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.normalize = normalize\n",
    "        self.is_lb = is_lb\n",
    "        self.label_map = {'Benign': 0, 'Malignant': 1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.dataframe.iloc[index]['file_path']\n",
    "        image = PIL.Image.open(img_path)\n",
    "\n",
    "        if self.is_lb:\n",
    "            label = self.label_map[self.dataframe.iloc[index]['label']]\n",
    "            return self.normalize(image), label\n",
    "        else:\n",
    "            return self.normalize(image), self.normalize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e621e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.630314Z",
     "iopub.status.busy": "2025-07-18T14:25:44.630056Z",
     "iopub.status.idle": "2025-07-18T14:25:44.645683Z",
     "shell.execute_reply": "2025-07-18T14:25:44.644915Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.630292Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "train_batch = 32\n",
    "val_batch = 8\n",
    "\n",
    "def data_transfrom():\n",
    "    normalize = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataset = ImageDataset(\n",
    "        train_dataframe,\n",
    "        normalize,\n",
    "        is_lb=True\n",
    "    )\n",
    "\n",
    "    valid_dataset = ImageDataset(\n",
    "        valid_dataframe,\n",
    "        normalize,\n",
    "        is_lb=True\n",
    "    )\n",
    "\n",
    "    dataloader_train_dataset = DataLoader(train_dataset, batch_size=train_batch, shuffle=True, num_workers=2)\n",
    "    dataloader_valid_dataset = DataLoader(valid_dataset, batch_size=val_batch, shuffle=False, num_workers=2)\n",
    "\n",
    "    return dataloader_train_dataset, dataloader_valid_dataset\n",
    "\n",
    "dataloader_train_dataset, dataloader_valid_dataset = data_transfrom()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915d34b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Neural Network (ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c1e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:44.646998Z",
     "iopub.status.busy": "2025-07-18T14:25:44.646643Z",
     "iopub.status.idle": "2025-07-18T14:25:45.266448Z",
     "shell.execute_reply": "2025-07-18T14:25:45.265579Z",
     "shell.execute_reply.started": "2025-07-18T14:25:44.646980Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_class = 2\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = models.ConvNeXt(pretrained=True)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, total_class)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "summary(model, input_size=(train_batch, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc461d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:25:45.267858Z",
     "iopub.status.busy": "2025-07-18T14:25:45.267497Z",
     "iopub.status.idle": "2025-07-18T14:30:29.034862Z",
     "shell.execute_reply": "2025-07-18T14:30:29.033869Z",
     "shell.execute_reply.started": "2025-07-18T14:25:45.267765Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloader_train_dataset, dataloader_valid_dataset, num_epochs=50, early_stop_patience=5, save_path_checkpoints=\"checkpoints\"):\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    consecutive_no_improvement = 0\n",
    "    num_epochs_loss_greater = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        progress_bar = tqdm(enumerate(dataloader_train_dataset), total=len(dataloader_train_dataset))\n",
    "        for i, (inputs, labels) in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            progress_bar.set_postfix(loss=running_loss / total_train, acc=correct_train / total_train)\n",
    "        epoch_train_loss = running_loss / total_train\n",
    "        epoch_train_acc = correct_train / total_train\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "        train_acc_history.append(epoch_train_acc)\n",
    "\n",
    "        print('Training Loss: {:.3f} Acc: {:.3f}'.format(epoch_train_loss, epoch_train_acc))\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader_valid_dataset:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = running_loss / total_val\n",
    "        epoch_val_acc = correct_val / total_val\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "        val_acc_history.append(epoch_val_acc)\n",
    "\n",
    "        print('Validation Loss: {:.3f} Acc: {:.3f}'.format(epoch_val_loss, epoch_val_acc))\n",
    "\n",
    "        # Check for early stopping\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            filepath = f\"{save_path_checkpoints}/model.pt\"\n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_weight\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, filepath)\n",
    "            print(f\"Best model saved at epoch {best_epoch} with validation accuracy: {best_val_acc:.3f}\")\n",
    "            consecutive_no_improvement = 0\n",
    "        else:\n",
    "            consecutive_no_improvement += 1\n",
    "\n",
    "        if epoch_val_loss > epoch_train_loss:\n",
    "            num_epochs_loss_greater += 1\n",
    "        else:\n",
    "            num_epochs_loss_greater = 0\n",
    "\n",
    "        if consecutive_no_improvement >= early_stop_patience or num_epochs_loss_greater >= early_stop_patience:\n",
    "            print(f\"Early stopping criteria met. No improvement in validation accuracy or validation loss for {early_stop_patience} consecutive epochs. Training stopped.\")\n",
    "            break\n",
    "\n",
    "    return train_loss_history, train_acc_history, val_loss_history, val_acc_history\n",
    "\n",
    "\n",
    "train_loss_history, train_acc_history, val_loss_history, val_acc_history = train_model(model, criterion, optimizer, dataloader_train_dataset, dataloader_valid_dataset, save_path_checkpoints=save_path_checkpoints)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds ---> {training_time/60:.2f} minutes\")\n",
    "\n",
    "data = {\n",
    "    'Epoch': list(range(1, len(train_loss_history) + 1)),\n",
    "    'Train Loss': train_loss_history,\n",
    "    'Train Accuracy': train_acc_history,\n",
    "    'Validation Loss': val_loss_history,\n",
    "    'Validation Accuracy': val_acc_history\n",
    "}\n",
    "\n",
    "history = pd.DataFrame(data)\n",
    "history.to_excel('/kaggle/working/training_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562ba65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:30:29.036907Z",
     "iopub.status.busy": "2025-07-18T14:30:29.036254Z",
     "iopub.status.idle": "2025-07-18T14:30:29.306707Z",
     "shell.execute_reply": "2025-07-18T14:30:29.306030Z",
     "shell.execute_reply.started": "2025-07-18T14:30:29.036879Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = pd.read_excel('/kaggle/working/training_data.xlsx')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['Epoch'], history['Train Loss'], label='Train Loss')\n",
    "plt.plot(history['Validation Loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.ylim(0,2)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['Epoch'], history['Train Accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['Validation Accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
    "plt.ylim(0,1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c93ab93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:30:29.307794Z",
     "iopub.status.busy": "2025-07-18T14:30:29.307529Z",
     "iopub.status.idle": "2025-07-18T14:30:29.313143Z",
     "shell.execute_reply": "2025-07-18T14:30:29.312572Z",
     "shell.execute_reply.started": "2025-07-18T14:30:29.307777Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e80a32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349ef6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:30:29.314384Z",
     "iopub.status.busy": "2025-07-18T14:30:29.313988Z",
     "iopub.status.idle": "2025-07-18T14:30:38.356532Z",
     "shell.execute_reply": "2025-07-18T14:30:38.355430Z",
     "shell.execute_reply.started": "2025-07-18T14:30:29.314358Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_checkpoint_path = f\"{save_path_checkpoints}/model.pt\"\n",
    "checkpoint = torch.load(best_checkpoint_path)\n",
    "best_epoch = checkpoint[\"epoch\"]\n",
    "model.load_state_dict(checkpoint[\"model_weight\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "\n",
    "best_val_loss, best_val_accuracy = evaluate_model(model, criterion, dataloader_valid_dataset)\n",
    "print(f\"Best model (from epoch {best_epoch}) - Validation Loss: {best_val_loss:.3f}, Validation Accuracy: {best_val_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79568fce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:30:38.358874Z",
     "iopub.status.busy": "2025-07-18T14:30:38.357906Z",
     "iopub.status.idle": "2025-07-18T14:31:28.465434Z",
     "shell.execute_reply": "2025-07-18T14:31:28.464582Z",
     "shell.execute_reply.started": "2025-07-18T14:30:38.358842Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def class_accuracy(model, dataloader, num_classes):\n",
    "    class_correct = [0.0] * num_classes\n",
    "    class_total = [0.0] * num_classes\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == labels)\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += correct[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    class_accuracy = [class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(num_classes)]\n",
    "    return class_accuracy\n",
    "\n",
    "def evaluate_model(model, dataloader, num_classes, dataset_name=\"Dataset\"):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    class_names = [str(i) for i in range(num_classes)]\n",
    "\n",
    "    print(f\"\\n=== {dataset_name} Classification Report ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    class_acc = class_accuracy(model, dataloader, num_classes)\n",
    "    for i in range(num_classes):\n",
    "        print(f\"{dataset_name} - Class {i} Accuracy: {class_acc[i]:.3f}\")\n",
    "\n",
    "# Run evaluation for both train and validation\n",
    "evaluate_model(model, dataloader_train_dataset, 2, dataset_name=\"Train\")\n",
    "evaluate_model(model, dataloader_valid_dataset, 2, dataset_name=\"Validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54a88c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:28.466886Z",
     "iopub.status.busy": "2025-07-18T14:31:28.466606Z",
     "iopub.status.idle": "2025-07-18T14:31:28.492695Z",
     "shell.execute_reply": "2025-07-18T14:31:28.492047Z",
     "shell.execute_reply.started": "2025-07-18T14:31:28.466859Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir1 = \"/kaggle/input/melanoma-cancer-dataset/test\"\n",
    "\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        file_paths.append(os.path.join(class_dir, image_name))\n",
    "        labels.append(class_name)\n",
    "\n",
    "df1 = pd.DataFrame({\"file_path\": file_paths, \"label\": labels})\n",
    "df1 = df1.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2ca4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:28.493890Z",
     "iopub.status.busy": "2025-07-18T14:31:28.493557Z",
     "iopub.status.idle": "2025-07-18T14:31:28.623705Z",
     "shell.execute_reply": "2025-07-18T14:31:28.622997Z",
     "shell.execute_reply.started": "2025-07-18T14:31:28.493864Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_counts_train = df1['label'].value_counts()\n",
    "\n",
    "for class_name, count in class_counts_train.items():\n",
    "    print(f\"Class: {class_name}, Count: {count}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = class_counts_train.plot(kind='bar')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Amount of data')\n",
    "plt.xticks(rotation=360)\n",
    "for i, count in enumerate(class_counts_train):\n",
    "    ax.text(i, count + 5, str(count), ha='center')\n",
    "plt.ylim(0, max(class_counts_train) * 1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488945f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:28.624818Z",
     "iopub.status.busy": "2025-07-18T14:31:28.624514Z",
     "iopub.status.idle": "2025-07-18T14:31:29.034230Z",
     "shell.execute_reply": "2025-07-18T14:31:29.033393Z",
     "shell.execute_reply.started": "2025-07-18T14:31:28.624790Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = df1['label'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for idx, class_label in enumerate(classes):\n",
    "\n",
    "    class_df1 = df1[df1['label'] == class_label]\n",
    "\n",
    "    random_index = random.randint(0, len(class_df1) - 1)\n",
    "    random_row = class_df1.iloc[random_index]\n",
    "\n",
    "    file_path = random_row['file_path']\n",
    "    label = random_row['label']\n",
    "\n",
    "    image = Image.open(file_path)\n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].set_title(f\"Label: {label}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884b9c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.035683Z",
     "iopub.status.busy": "2025-07-18T14:31:29.035228Z",
     "iopub.status.idle": "2025-07-18T14:31:29.053681Z",
     "shell.execute_reply": "2025-07-18T14:31:29.052934Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.035663Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "rest_dataframe, test_df1 = train_test_split(\n",
    "    df1,\n",
    "    test_size=0.30,\n",
    "    stratify=df1['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Remaining Data (for training/validation):\", len(rest_dataframe))\n",
    "print(\"Test Data:\", len(test_df1))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Total data in dataset:\", len(df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9149f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.054996Z",
     "iopub.status.busy": "2025-07-18T14:31:29.054619Z",
     "iopub.status.idle": "2025-07-18T14:31:29.060220Z",
     "shell.execute_reply": "2025-07-18T14:31:29.059446Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.054963Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Test Data: \", len(test_df1))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Total amounts of data in the dataset: \", len(df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1b198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.061428Z",
     "iopub.status.busy": "2025-07-18T14:31:29.061154Z",
     "iopub.status.idle": "2025-07-18T14:31:29.076732Z",
     "shell.execute_reply": "2025-07-18T14:31:29.075854Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.061386Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "class_counts_test = test_df1['label'].value_counts()\n",
    "test_table_data = [[class_name, count] for class_name, count in class_counts_test.items()]\n",
    "\n",
    "print(\"Test Dataset\")\n",
    "print(tabulate(test_table_data, headers=[\"Class\", \"Count\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16911b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.081305Z",
     "iopub.status.busy": "2025-07-18T14:31:29.081036Z",
     "iopub.status.idle": "2025-07-18T14:31:29.095267Z",
     "shell.execute_reply": "2025-07-18T14:31:29.094420Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.081286Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef46b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.096516Z",
     "iopub.status.busy": "2025-07-18T14:31:29.096199Z",
     "iopub.status.idle": "2025-07-18T14:31:29.119448Z",
     "shell.execute_reply": "2025-07-18T14:31:29.118619Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.096490Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path_checkpoints = \"/kaggle/working/\"\n",
    "os.makedirs(save_path_checkpoints, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e8430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.121070Z",
     "iopub.status.busy": "2025-07-18T14:31:29.120458Z",
     "iopub.status.idle": "2025-07-18T14:31:29.134238Z",
     "shell.execute_reply": "2025-07-18T14:31:29.133445Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.121041Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, normalize, is_lb=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.normalize = normalize\n",
    "        self.is_lb = is_lb\n",
    "        self.label_map = {'Benign': 0, 'Malignant': 1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.dataframe.iloc[index]['file_path']\n",
    "        image = PIL.Image.open(img_path)\n",
    "\n",
    "        if self.is_lb:\n",
    "            label = self.label_map[self.dataframe.iloc[index]['label']]\n",
    "            return self.normalize(image), label\n",
    "        else:\n",
    "            return self.normalize(image), self.normalize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4deec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.135526Z",
     "iopub.status.busy": "2025-07-18T14:31:29.135229Z",
     "iopub.status.idle": "2025-07-18T14:31:29.148105Z",
     "shell.execute_reply": "2025-07-18T14:31:29.147343Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.135502Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "test_batch = 8  \n",
    "\n",
    "def data_transform_test_only():\n",
    "    normalize = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    test_dataset = ImageDataset(\n",
    "        test_df1,\n",
    "        normalize,\n",
    "        is_lb=True\n",
    "    )\n",
    "\n",
    "    dataloader_test_dataset = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=test_batch, \n",
    "        shuffle=False, \n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    return dataloader_test_dataset\n",
    "\n",
    "dataloader_test_dataset = data_transform_test_only()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225034e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.149139Z",
     "iopub.status.busy": "2025-07-18T14:31:29.148876Z",
     "iopub.status.idle": "2025-07-18T14:31:29.714712Z",
     "shell.execute_reply": "2025-07-18T14:31:29.713889Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.149121Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_class = 2\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = models.ConvNeXt(pretrained=True)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, total_class)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "summary(model, input_size=(test_batch, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d67c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:29.715858Z",
     "iopub.status.busy": "2025-07-18T14:31:29.715576Z",
     "iopub.status.idle": "2025-07-18T14:31:38.539808Z",
     "shell.execute_reply": "2025-07-18T14:31:38.538940Z",
     "shell.execute_reply.started": "2025-07-18T14:31:29.715831Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------ TEST EVALUATION ------------------\n",
    "\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader_test_dataset:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "test_accuracy = correct_test / total_test\n",
    "\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.3f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "# Optionally, add to Excel sheet\n",
    "test_summary = pd.DataFrame({\n",
    "    \"Metric\": [\"Test Loss\", \"Test Accuracy\"],\n",
    "    \"Value\": [avg_test_loss, test_accuracy]\n",
    "})\n",
    "\n",
    "# Save both training history and test results\n",
    "with pd.ExcelWriter('/kaggle/working/training_data_with_test.xlsx') as writer:\n",
    "    history.to_excel(writer, index=False, sheet_name='Train_Val_History')\n",
    "    test_summary.to_excel(writer, index=False, sheet_name='Test_Summary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad7821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:38.541673Z",
     "iopub.status.busy": "2025-07-18T14:31:38.540920Z",
     "iopub.status.idle": "2025-07-18T14:31:38.817753Z",
     "shell.execute_reply": "2025-07-18T14:31:38.816987Z",
     "shell.execute_reply.started": "2025-07-18T14:31:38.541646Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = pd.read_excel('/kaggle/working/training_data.xlsx')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['Epoch'], history['Train Loss'], label='Train Loss')\n",
    "plt.plot(history['Validation Loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.ylim(0,2)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['Epoch'], history['Train Accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['Validation Accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
    "plt.ylim(0,1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91385669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:38.819047Z",
     "iopub.status.busy": "2025-07-18T14:31:38.818743Z",
     "iopub.status.idle": "2025-07-18T14:31:38.825064Z",
     "shell.execute_reply": "2025-07-18T14:31:38.824508Z",
     "shell.execute_reply.started": "2025-07-18T14:31:38.819026Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe2cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:38.826207Z",
     "iopub.status.busy": "2025-07-18T14:31:38.825935Z",
     "iopub.status.idle": "2025-07-18T14:31:47.916328Z",
     "shell.execute_reply": "2025-07-18T14:31:47.915321Z",
     "shell.execute_reply.started": "2025-07-18T14:31:38.826185Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_checkpoint_path = f\"{save_path_checkpoints}/model.pt\"\n",
    "checkpoint = torch.load(best_checkpoint_path)\n",
    "best_epoch = checkpoint[\"epoch\"]\n",
    "model.load_state_dict(checkpoint[\"model_weight\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "\n",
    "best_val_loss, best_val_accuracy = evaluate_model(model, criterion, dataloader_valid_dataset)\n",
    "print(f\"Best model (from epoch {best_epoch}) - Validation Loss: {best_val_loss:.3f}, Validation Accuracy: {best_val_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76792507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:31:47.917913Z",
     "iopub.status.busy": "2025-07-18T14:31:47.917605Z",
     "iopub.status.idle": "2025-07-18T14:32:05.623004Z",
     "shell.execute_reply": "2025-07-18T14:32:05.622184Z",
     "shell.execute_reply.started": "2025-07-18T14:31:47.917879Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def class_accuracy(model, dataloader, num_classes):\n",
    "    class_correct = [0.0] * num_classes\n",
    "    class_total = [0.0] * num_classes\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == labels)\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += correct[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    class_accuracy = [class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(num_classes)]\n",
    "\n",
    "    return class_accuracy\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader_test_dataset:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "class_names = [str(i) for i in range(total_class)]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "class_acc = class_accuracy(model, dataloader_test_dataset, total_class)\n",
    "for i in range(total_class):\n",
    "    print(f\"Class {i} Accuracy: {class_acc[i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.237496,
   "end_time": "2025-08-08T13:43:58.453484",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-08T13:43:28.215988",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
