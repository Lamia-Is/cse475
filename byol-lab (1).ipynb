{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":7649273,"sourceType":"datasetVersion","datasetId":4459076}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport copy\nimport math\nimport random\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\n\nimport numpy as np\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom google.colab import drive\n\n# --- Configuration ---\nBATCH_SIZE = 64         \nEPOCHS_PRETRAIN = 10    \nEPOCHS_LINEAR_EVAL = 10 \nLEARNING_RATE = 3e-4    \nWEIGHT_DECAY = 1e-6     \nPROJECTION_DIM = 128   \nHIDDEN_DIM = 512     \nMOMENTUM_BASE = 0.99   \nNUM_WORKERS = 2        \n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nPIN_MEMORY = True if DEVICE.type == 'cuda' else False\n\nprint(f\"Using device: {DEVICE}\")\n\n# Set seeds for reproducibility\nSEED = 42\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# For reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSlX0Qy1JLVR","outputId":"e8340455-42bf-4ae7-a221-217797d1ea22","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T06:18:25.225423Z","iopub.execute_input":"2025-07-23T06:18:25.225727Z","iopub.status.idle":"2025-07-23T06:18:25.234204Z","shell.execute_reply.started":"2025-07-23T06:18:25.225705Z","shell.execute_reply":"2025-07-23T06:18:25.233661Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"Dataset = \"/kaggle/input/melanoma-cancer-dataset\"\n\nfile_paths = []\nlabels = []\n\nfor class_name in os.listdir(Dataset):\n    class_dir = os.path.join(Dataset, class_name)\n    for image_name in os.listdir(class_dir):\n        file_paths.append(os.path.join(class_dir, image_name))\n        labels.append(class_name)\n\ndf = pd.DataFrame({\"file_path\": file_paths, \"label\": labels})\ndf = df.sample(frac=1).reset_index(drop=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r4S-nEHIXCi3","outputId":"cf2e8954-0988-412a-9e45-956fc022c516","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T06:18:25.235512Z","iopub.execute_input":"2025-07-23T06:18:25.235725Z","iopub.status.idle":"2025-07-23T06:18:25.260828Z","shell.execute_reply.started":"2025-07-23T06:18:25.235709Z","shell.execute_reply":"2025-07-23T06:18:25.260160Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# @title 2. BYOL Data Augmentations\n# This cell defines the custom data augmentation pipeline for BYOL.\n\nclass CustomBYOLTransform:\n    def __init__(self, size=32):\n        # ImageNet stats for normalization\n        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                         std=[0.229, 0.224, 0.225])\n\n        # Core augmentations for BYOL (similar to SimCLR)\n        self.transform1 = transforms.Compose([\n            transforms.RandomResizedCrop(size=size, scale=(0.2, 1.0)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.RandomApply([transforms.GaussianBlur(kernel_size=int(0.1 * size))], p=0.5), # Crucial for BYOL\n            transforms.ToTensor(),\n            normalize\n        ])\n\n        # Often a slightly different set of augmentations for the second view\n        # or just a different random application of the same ones.\n        self.transform2 = transforms.Compose([\n            transforms.RandomResizedCrop(size=size, scale=(0.2, 1.0)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.RandomApply([transforms.GaussianBlur(kernel_size=int(0.1 * size))], p=0.5), # Crucial for BYOL\n            transforms.ToTensor(),\n            normalize\n        ])\n\n    def __call__(self, x):\n        return self.transform1(x), self.transform2(x)\n\n# CIFAR-10 dataset with custom BYOL transformations\nclass CIFAR10BYOL(datasets.CIFAR10):\n    def __init__(self, root, train=True, transform=None, download=False):\n        super().__init__(root, train=train, transform=transform, download=download)\n\n    def __getitem__(self, index):\n        img, target = self.data[index], self.targets[index]\n        img = Image.fromarray(img)\n\n        if self.transform is not None:\n            # Return two augmented views of the same image\n            return self.transform(img)\n        else:\n            return img, target\n\n# Load CIFAR-10 dataset\ntrain_dataset_byol = CIFAR10BYOL(root='./data', train=True, download=True, transform=CustomBYOLTransform())\ntrain_loader_byol = DataLoader(train_dataset_byol, batch_size=BATCH_SIZE, shuffle=True,\n                               num_workers=NUM_WORKERS, drop_last=True, pin_memory=True)\n\n# Dataset for linear evaluation (standard transforms)\ntrain_transform_eval = transforms.Compose([\n    transforms.RandomResizedCrop(32),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntest_transform_eval = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset_eval = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform_eval)\ntest_dataset_eval = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform_eval)\n\ntrain_loader_eval = DataLoader(train_dataset_eval, batch_size=BATCH_SIZE, shuffle=True,\n                               num_workers=NUM_WORKERS, pin_memory=True)\ntest_loader_eval = DataLoader(test_dataset_eval, batch_size=BATCH_SIZE, shuffle=False,\n                              num_workers=NUM_WORKERS, pin_memory=True)\n\nprint(f\"BYOL training dataset size: {len(train_dataset_byol)}\")\nprint(f\"Linear evaluation training dataset size: {len(train_dataset_eval)}\")\nprint(f\"Linear evaluation test dataset size: {len(test_dataset_eval)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qMEp5z-8JkAk","outputId":"4ce90fb0-d5aa-4142-fc68-391f2d85339d","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T06:18:25.261427Z","iopub.execute_input":"2025-07-23T06:18:25.261621Z","iopub.status.idle":"2025-07-23T06:18:32.478209Z","shell.execute_reply.started":"2025-07-23T06:18:25.261606Z","shell.execute_reply":"2025-07-23T06:18:32.477454Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 170M/170M [00:02<00:00, 60.0MB/s] \n","output_type":"stream"},{"name":"stdout","text":"BYOL training dataset size: 50000\nLinear evaluation training dataset size: 50000\nLinear evaluation test dataset size: 10000\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# @title 3. BYOL Model Components\n# This cell defines the encoder, projector, and predictor networks.\n\nclass BYOLResNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Use a pre-trained ResNet-50 as the backbone, but modify for CIFAR-10\n        # CIFAR-10 images are 32x32, so initial layers need adjustment or can be kept as is\n        # and rely on RandomResizedCrop to handle the size.\n        # ResNet default initial layers are designed for 224x224.\n        # For CIFAR-10, often the first maxpool is removed, and stride of conv1 is reduced.\n        # For simplicity here, we'll use the default ResNet-50 and let torchvision handle initial layers.\n        # However, for optimal CIFAR performance, you might adapt initial layers.\n\n        # Use ResNet-50\n        resnet = models.resnet50(weights=None) # Start without pre-trained ImageNet weights\n\n        # Remove the final fully connected layer (classifier)\n        self.encoder = nn.Sequential(*list(resnet.children())[:-1])\n\n        # Get feature dimension from the flattened output of the encoder\n        # For ResNet-50, output before FC layer is 2048 feature maps.\n        # After global average pooling, it's 2048.\n        self.feature_dim = 2048\n\n    def forward(self, x):\n        return self.encoder(x).view(x.size(0), -1) # Flatten the output\n\nclass ProjectionHead(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass PredictionHead(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n# Main BYOL Model\nclass BYOL(nn.Module):\n    def __init__(self, encoder: BYOLResNet, projection_dim, hidden_dim):\n        super().__init__()\n        self.online_encoder = encoder\n        self.online_projector = ProjectionHead(encoder.feature_dim, hidden_dim, projection_dim)\n        self.online_predictor = PredictionHead(projection_dim, hidden_dim, projection_dim)\n\n        self.target_encoder = copy.deepcopy(encoder)\n        self.target_projector = copy.deepcopy(self.online_projector)\n\n        # Freeze target network parameters\n        for param in self.target_encoder.parameters():\n            param.requires_grad = False\n        for param in self.target_projector.parameters():\n            param.requires_grad = False\n\n    def forward(self, x1, x2):\n        # Online network forward pass\n        online_proj_out1 = self.online_projector(self.online_encoder(x1))\n        online_pred_out1 = self.online_predictor(online_proj_out1)\n\n        online_proj_out2 = self.online_projector(self.online_encoder(x2))\n        online_pred_out2 = self.online_predictor(online_proj_out2)\n\n        # Target network forward pass (no gradients needed for target)\n        with torch.no_grad():\n            target_proj_out1 = self.target_projector(self.target_encoder(x1))\n            target_proj_out2 = self.target_projector(self.target_encoder(x2))\n\n        return online_pred_out1, online_pred_out2, target_proj_out1, target_proj_out2\n\n    # EMA update for target network\n    def update_target_network(self, momentum):\n        for online_param, target_param in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n            target_param.data = target_param.data * momentum + online_param.data * (1. - momentum)\n        for online_param, target_param in zip(self.online_projector.parameters(), self.target_projector.parameters()):\n            target_param.data = target_param.data * momentum + online_param.data * (1. - momentum)\n\n# Instantiate the BYOL model\nbyol_encoder = BYOLResNet().to(DEVICE)\nbyol_model = BYOL(byol_encoder, PROJECTION_DIM, HIDDEN_DIM).to(DEVICE)\n\n# Check model architecture\nprint(byol_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTHgruFdJqat","outputId":"e67cbe00-c0b2-4dc1-d1d2-8ab690ca4abd","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T06:18:32.479577Z","iopub.execute_input":"2025-07-23T06:18:32.479799Z","iopub.status.idle":"2025-07-23T06:18:32.923212Z","shell.execute_reply.started":"2025-07-23T06:18:32.479783Z","shell.execute_reply":"2025-07-23T06:18:32.922459Z"}},"outputs":[{"name":"stdout","text":"BYOL(\n  (online_encoder): BYOLResNet(\n    (encoder): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (5): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (6): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (7): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n    )\n  )\n  (online_projector): ProjectionHead(\n    (net): Sequential(\n      (0): Linear(in_features=2048, out_features=512, bias=True)\n      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Linear(in_features=512, out_features=128, bias=True)\n    )\n  )\n  (online_predictor): PredictionHead(\n    (net): Sequential(\n      (0): Linear(in_features=128, out_features=512, bias=True)\n      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Linear(in_features=512, out_features=128, bias=True)\n    )\n  )\n  (target_encoder): BYOLResNet(\n    (encoder): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (5): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (6): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (7): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n    )\n  )\n  (target_projector): ProjectionHead(\n    (net): Sequential(\n      (0): Linear(in_features=2048, out_features=512, bias=True)\n      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Linear(in_features=512, out_features=128, bias=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# @title 4. BYOL Loss Function\n# This cell defines the custom BYOL loss.\n\ndef byol_loss(online_pred, target_proj):\n    # Normalize outputs before computing MSE\n    online_pred_norm = F.normalize(online_pred, dim=-1)\n    target_proj_norm = F.normalize(target_proj, dim=-1)\n\n    # Negative MSE loss as per BYOL paper (L2 norm squared)\n    # The paper uses 1 - cosine_similarity as their loss equivalent to this,\n    # which leads to this form.\n    loss = 2 - 2 * (online_pred_norm * target_proj_norm).sum(dim=-1)\n    return loss.mean()","metadata":{"id":"JDU53LU0JzrR","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T06:18:32.924134Z","iopub.execute_input":"2025-07-23T06:18:32.924350Z","iopub.status.idle":"2025-07-23T06:18:32.928758Z","shell.execute_reply.started":"2025-07-23T06:18:32.924334Z","shell.execute_reply":"2025-07-23T06:18:32.927974Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# @title 5. Self-Supervised Pre-training Loop\n# This cell contains the main training logic for BYOL.\n\ndef adjust_learning_rate(optimizer, init_lr, epoch, total_epochs):\n    \"\"\"Cosine learning rate decay\"\"\"\n    lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / total_epochs))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\ndef adjust_momentum(epoch, total_epochs, momentum_base):\n    \"\"\"Momentum annealing for EMA\"\"\"\n    m = 1. - (1. - momentum_base) * (math.cos(math.pi * epoch / total_epochs) + 1) / 2\n    return m\n\nprint(\"--- Starting BYOL Self-Supervised Pre-training ---\")\noptimizer = optim.AdamW(byol_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_PRETRAIN, eta_min=0)\n\npretrain_losses = []\n\nfor epoch in range(1, EPOCHS_PRETRAIN + 1):\n    byol_model.train()\n    total_loss = 0.0\n    start_time = time.time()\n\n    # Adjust learning rate (cosine decay)\n    adjust_learning_rate(optimizer, LEARNING_RATE, epoch, EPOCHS_PRETRAIN)\n\n    # Adjust momentum for target network (cosine annealing)\n    current_momentum = adjust_momentum(epoch, EPOCHS_PRETRAIN, MOMENTUM_BASE)\n\n    for (x1, x2) in train_loader_byol:\n        x1, x2 = x1.to(DEVICE), x2.to(DEVICE)\n\n        optimizer.zero_grad()\n\n        # Forward pass through BYOL model\n        online_pred_out1, online_pred_out2, target_proj_out1, target_proj_out2 = byol_model(x1, x2)\n\n        # Calculate loss (symmetric loss)\n        loss1 = byol_loss(online_pred_out1, target_proj_out2)\n        loss2 = byol_loss(online_pred_out2, target_proj_out1)\n        loss = loss1 + loss2 # Sum of two symmetric loss terms\n\n        loss.backward()\n        optimizer.step()\n\n        # Update target network parameters using EMA\n        byol_model.update_target_network(current_momentum)\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader_byol)\n    pretrain_losses.append(avg_loss)\n    elapsed_time = time.time() - start_time\n\n    print(f\"Pretrain Epoch {epoch}/{EPOCHS_PRETRAIN} | Loss: {avg_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f} | Momentum: {current_momentum:.4f} | Time: {elapsed_time:.1f}s\")\n\nprint(\"--- BYOL Self-Supervised Pre-training Finished ---\")\n\n# Save the pre-trained encoder weights\ntorch.save(byol_model.online_encoder.state_dict(), os.path.join(Dataset, \"byol_encoder_cifar10.pth\"))\nprint(f\"Saved pre-trained encoder to {os.path.join(Dataset, 'byol_encoder_cifar10.pth')}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzxte-WVJ8Jt","outputId":"33b298c9-0a56-4899-f197-85448d7efaf4","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T06:18:32.929580Z","iopub.execute_input":"2025-07-23T06:18:32.929857Z"}},"outputs":[{"name":"stdout","text":"--- Starting BYOL Self-Supervised Pre-training ---\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# @title 6. Linear Evaluation (Downstream Task)\n# This cell defines a linear classifier and evaluates the pre-trained encoder.\n\nclass LinearClassifier(nn.Module):\n    def __init__(self, feature_dim, num_classes=10):\n        super().__init__()\n        self.fc = nn.Linear(feature_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\nprint(\"\\n--- Starting Linear Evaluation ---\")\n\n# Load the pre-trained encoder\n# The encoder is the 'online_encoder' from the BYOL model\npretrained_encoder = BYOLResNet().to(DEVICE)\npretrained_encoder.load_state_dict(torch.load(os.path.join(Dataset, \"byol_encoder_cifar10.pth\")))\n\n# Freeze the encoder's parameters\nfor param in pretrained_encoder.parameters():\n    param.requires_grad = False\n\n# Attach a new linear classifier head\nclassifier = LinearClassifier(pretrained_encoder.feature_dim, num_classes=10).to(DEVICE)\n\n# Only optimize the classifier's parameters\noptimizer_eval = optim.Adam(classifier.parameters(), lr=LEARNING_RATE)\ncriterion_eval = nn.CrossEntropyLoss()\n\nlinear_eval_train_losses = []\nlinear_eval_test_accuracies = []\n\nfor epoch in range(1, EPOCHS_LINEAR_EVAL + 1):\n    classifier.train()\n    total_loss = 0.0\n    start_time = time.time()\n\n    for images, labels in train_loader_eval:\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        optimizer_eval.zero_grad()\n\n        with torch.no_grad(): # Ensure encoder remains frozen\n            features = pretrained_encoder(images)\n\n        outputs = classifier(features)\n        loss = criterion_eval(outputs, labels)\n\n        loss.backward()\n        optimizer_eval.step()\n        total_loss += loss.item()\n\n    avg_train_loss = total_loss / len(train_loader_eval)\n    linear_eval_train_losses.append(avg_train_loss)\n\n    # Evaluation on test set\n    classifier.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader_eval:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            features = pretrained_encoder(images) # Use the frozen encoder\n            outputs = classifier(features)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    linear_eval_test_accuracies.append(accuracy)\n\n    elapsed_time = time.time() - start_time\n    print(f\"Linear Eval Epoch {epoch}/{EPOCHS_LINEAR_EVAL} | Train Loss: {avg_train_loss:.4f} | Test Acc: {accuracy:.2f}% | Time: {elapsed_time:.1f}s\")\n\nprint(\"--- Linear Evaluation Finished ---\")\n\n# Optional: Train a randomly initialized encoder + classifier as a baseline for comparison\nprint(\"\\n--- Training Baseline (Randomly Initialized Encoder) ---\")\nrandom_encoder = BYOLResNet().to(DEVICE) # New, random encoder\nrandom_classifier = LinearClassifier(random_encoder.feature_dim, num_classes=10).to(DEVICE)\nrandom_model = nn.Sequential(random_encoder, random_classifier).to(DEVICE) # Treat as one model for simplicity\n\noptimizer_random = optim.Adam(random_model.parameters(), lr=LEARNING_RATE)\ncriterion_random = nn.CrossEntropyLoss()\n\nrandom_eval_test_accuracies = []\n\nfor epoch in range(1, EPOCHS_LINEAR_EVAL + 1):\n    random_model.train()\n    for images, labels in train_loader_eval:\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        optimizer_random.zero_grad()\n        outputs = random_model(images)\n        loss = criterion_random(outputs, labels)\n        loss.backward()\n        optimizer_random.step()\n\n    random_model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader_eval:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = random_model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    random_eval_test_accuracies.append(accuracy)\n\n    if epoch % 10 == 0 or epoch == EPOCHS_LINEAR_EVAL:\n        print(f\"Random Baseline Eval Epoch {epoch}/{EPOCHS_LINEAR_EVAL} | Test Acc: {accuracy:.2f}%\")\n\nprint(\"--- Random Baseline Training Finished ---\")","metadata":{"id":"e5DgLvmwKAGM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"edc71d33-9cb0-4bd4-d321-c347c04cadf4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# @title 7. Visualization of Impact\n# This cell provides code to visualize the training loss and embedding space.\n\n# --- Loss Curve ---\nplt.figure(figsize=(10, 5))\nplt.plot(pretrain_losses, label='BYOL Pre-training Loss')\nplt.title('BYOL Self-Supervised Pre-training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.grid(True)\nplt.legend()\nplt.savefig(os.path.join(Dataset, \"byol_pretrain_loss.png\"))\nplt.show()\n\nplt.figure(figsize=(10, 5))\nplt.plot(linear_eval_test_accuracies, label='BYOL Pre-trained + Linear Eval Acc')\nplt.plot(random_eval_test_accuracies, label='Random Init + Full Train Acc')\nplt.title('Linear Evaluation Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.grid(True)\nplt.legend()\nplt.savefig(os.path.join(Dataset, \"linear_eval_accuracy.png\"))\nplt.show()\n\n# --- Embedding Space Visualization (t-SNE) ---\nprint(\"\\n--- Visualizing Embedding Space with t-SNE ---\")\n\n# Get embeddings from a subset of the test set\n# It's computationally expensive to run t-SNE on all 10,000 images.\n# Let's use 1000 images for visualization.\nnum_samples_tsne = 1000\nsubset_dataset_eval = torch.utils.data.Subset(test_dataset_eval, range(num_samples_tsne))\nsubset_loader_eval = DataLoader(subset_dataset_eval, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\npretrained_encoder.eval() # Set encoder to evaluation mode\nembeddings = []\nlabels = []\n\nwith torch.no_grad():\n    for images, targets in subset_loader_eval:\n        images = images.to(DEVICE)\n        features = pretrained_encoder(images)\n        embeddings.append(features.cpu().numpy())\n        labels.append(targets.cpu().numpy())\n\nembeddings = np.vstack(embeddings)\nlabels = np.concatenate(labels)\n\nprint(f\"Running t-SNE on {embeddings.shape[0]} embeddings...\")\ntsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\nembeddings_2d = tsne.fit_transform(embeddings)\n\n# Plotting the t-SNE results\nplt.figure(figsize=(12, 10))\nsns.scatterplot(\n    x=embeddings_2d[:, 0], y=embeddings_2d[:, 1],\n    hue=labels, palette=sns.color_palette(\"tab10\", 10),\n    legend='full', alpha=0.7\n)\nplt.title('BYOL Pre-trained CIFAR-10 Embeddings (t-SNE)')\nplt.xlabel('t-SNE Component 1')\nplt.ylabel('t-SNE Component 2')\nplt.grid(True)\nplt.savefig(os.path.join(Dataset, \"byol_embeddings_tsne.png\"))\nplt.show()\n\n# --- Discussing the Impact with Students ---\nprint(\"\\n--- Discussing the Impact of BYOL ---\")\nprint(\"1. Self-Supervised Pre-training Loss Curve:\")\nprint(\"   - Show how the BYOL loss (a combination of MSE on normalized predictions) smoothly decreases, indicating the model is learning to predict the target network's output.\")\nprint(\"   - Emphasize that this happens *without any human labels*.\")\nprint(\"   - Contrast with supervised learning loss curves that rely on explicit labels.\")\n\nprint(\"\\n2. Linear Evaluation Accuracy:\")\nprint(f\"   - **BYOL Pre-trained Encoder Accuracy: {linear_eval_test_accuracies[-1]:.2f}%**\")\nprint(f\"   - **Randomly Initialized Encoder Accuracy: {random_eval_test_accuracies[-1]:.2f}%**\")\nprint(\"   - Highlight the significant performance gap.\")\nprint(\"   - Explain that BYOL's pre-training forces the encoder to learn *general-purpose, semantically rich features* (like edges, textures, object parts) that are useful for downstream tasks (like classification) without ever seeing a single label.\")\nprint(\"   - Contrast with the 'random' baseline, which learns everything from scratch with limited labeled data, often performing much worse.\")\n\nprint(\"\\n3. Embedding Space Visualization (t-SNE):\")\nprint(\"   - Show the t-SNE plot where points are colored by their true CIFAR-10 classes.\")\nprint(\"   - Point out that even though BYOL never saw these labels, images from the same class tend to *cluster together* in the embedding space.\")\nprint(\"   - This visually demonstrates that the encoder has learned to group similar concepts, which is why it performs well in linear evaluation.\")\nprint(\"   - Explain that this 'clustering' means the representations are 'disentangled' or 'meaningful' for classification.\")\n\nprint(\"\\n4. Key Concepts of BYOL:\")\nprint(\"   - **No Negative Pairs:** Explain how BYOL elegantly avoids the need for computationally expensive negative samples, unlike SimCLR or MoCo.\")\nprint(\"   - **Target Network & EMA:** Describe the 'target network' as a slowly updated copy of the online network (Exponential Moving Average - EMA). This provides a stable target to predict, preventing trivial solutions (collapse).\")\nprint(\"   - **Predictor:** Explain the role of the predictor head in predicting the target's output, further preventing collapse by ensuring the online network's representation doesn't become too close to the target's immediately.\")\nprint(\"   - **Asymmetric Design:** Highlight the asymmetry between the online and target networks (online has a predictor, target uses EMA, stop-gradient on target).\")\n\nprint(\"\\nBy demonstrating these aspects, students can grasp the power of self-supervised learning, specifically BYOL, in learning effective representations from vast amounts of unlabeled data, a critical skill in modern AI.\")","metadata":{"id":"ubLeCo0SKEqs","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f4dbef91-8869-40ff-cb37-6c6a0adfa719","trusted":true},"outputs":[],"execution_count":null}]}